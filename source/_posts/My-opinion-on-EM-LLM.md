---
title: My opinion on LLM with Episodic Memory
published: 'true'
theme: xray
password: jz0218
abstract: hidden
categories:
  - 随笔
---

About a week ago, I have listened to a Lex Fridman Podcast with Charan Ranganath and took [notes](https://www.dropbox.com/scl/fi/syyudxamt538dr5d8w0c8/Notes-On-Lex-Podcast-with-Charan-Ranganath.pdf?rlkey=ojqml8088x73bnmzzsnap5aeu&st=0iyd1yu7&dl=0) on it.

I immediately thought it could be applied in LLMs, as many ideas that C.R. proposed are quite interesting, such as:
- Simillar neurons are used by the brain when predicting the future and remembering the past
- Humans don't replay the past, we imagine what the past could've been by taking bits and pieces
- "You don'w want to remember more, but better" (Remembering things at a higher abstract, cramming vs actually knowing)
  - Maybe there's something here
- He suggested [Internal Models of Events](#internal-models-of-events)
- Forgetting and Retrieval failure


### Internal Models of Events

Internal Models of Events are formed with both Semantic and Episodic memory at particular points of high prediction error. And those points are when its maximally optimal to encode as episodic memory.

# Thoughts

- wait do human store episodic memories for training while sleeping? 
- 
